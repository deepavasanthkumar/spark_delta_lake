{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "delta_quickstart.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNSWApS5f9F2eF5Z6msHQ/H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepavasanthkumar/spark_delta_lake/blob/main/delta_quickstart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#QuickStart to DeltaLake"
      ],
      "metadata": {
        "id": "aihC6-frzJOU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Delta Lake** is an open source storage layer that brings reliability to data lakes. Delta Lake provides ACID transactions, scalable metadata handling, and unifies streaming and batch data processing. Delta Lake runs on top of your existing data lake and is fully compatible with Apache Spark APIs. Delta Lake on Databricks allows you to configure Delta Lake based on your workload patterns."
      ],
      "metadata": {
        "id": "hAEu_Ik8zCqB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mY2W3OH4V0am",
        "outputId": "15c4805f-20c2-482e-e55d-58ce15a15649"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark==3.2.2\n",
            "  Downloading pyspark-3.2.2.tar.gz (281.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.5 MB 35 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 48.4 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.2-py2.py3-none-any.whl size=281969454 sha256=621766735828552d66e61b3c173282b9a721daf73e08bc1399c917db25b6bf4b\n",
            "  Stored in directory: /root/.cache/pip/wheels/f5/e6/d7/5216dc9246deb38346ab099a7f069df40f684fcd5968f44c0e\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark==3.2.2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "use pip install delta-spark and after successfull execution, **restart** runtime\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xnJh1gb2FCkc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install delta-spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "274DzZ5PgRxZ",
        "outputId": "d21a68d5-b818-455c-b1d8-493ddcdc36b4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting delta-spark\n",
            "  Downloading delta_spark-2.0.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: importlib-metadata>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from delta-spark) (4.12.0)\n",
            "Requirement already satisfied: pyspark<3.3.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from delta-spark) (3.2.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0.0->delta-spark) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0.0->delta-spark) (4.1.1)\n",
            "Requirement already satisfied: py4j==0.10.9.5 in /usr/local/lib/python3.7/dist-packages (from pyspark<3.3.0,>=3.2.0->delta-spark) (0.10.9.5)\n",
            "Installing collected packages: delta-spark\n",
            "Successfully installed delta-spark-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, expr\n",
        "from delta.tables import DeltaTable\n",
        "import shutil"
      ],
      "metadata": {
        "id": "D49MfZiZjNwN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.rmtree(\"/tmp/delta-table\", ignore_errors=True)"
      ],
      "metadata": {
        "id": "UCV-Bk3tjSsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating SparkSession with ***configure_spark_with_delta_pip***\n",
        "\n"
      ],
      "metadata": {
        "id": "SFS-6jdEbqit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from delta import *\n",
        "builder = SparkSession.builder.appName(\"DeltaLakeApp\") \\\n",
        "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
        "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\\\n",
        "    .config(\"spark.jars.packages\",\"io.delta:delta-core_2.12:2.0.0\")\n",
        "\n",
        "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
      ],
      "metadata": {
        "id": "syenlqFqI4Ez"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-bMNHgtIzAZg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Write Data"
      ],
      "metadata": {
        "id": "jRny_8qiZWB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = spark.range(0, 5)\n",
        "data.write.format(\"delta\").save(\"/tmp/delta-table\")"
      ],
      "metadata": {
        "id": "j5ZFJVPkjh5K"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Read Data"
      ],
      "metadata": {
        "id": "onQdjT8EZZTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.format(\"delta\").load(\"/tmp/delta-table\")\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiLe9GthZLjM",
        "outputId": "ea476866-e4cb-46ee-ffc3-225a6843d070"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+\n",
            "| id|\n",
            "+---+\n",
            "|  2|\n",
            "|  3|\n",
            "|  4|\n",
            "|  0|\n",
            "|  1|\n",
            "+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Upsert (merge) new data"
      ],
      "metadata": {
        "id": "Qph5zTwTbgoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "newData = spark.range(0, 20)\n",
        "\n",
        "deltaTable = DeltaTable.forPath(spark, \"/tmp/delta-table\")\n",
        "\n",
        "deltaTable.alias(\"oldData\")\\\n",
        "    .merge(\n",
        "    newData.alias(\"newData\"),\n",
        "    \"oldData.id = newData.id\")\\\n",
        "    .whenMatchedUpdate(set={\"id\": col(\"newData.id\")})\\\n",
        "    .whenNotMatchedInsert(values={\"id\": col(\"newData.id\")})\\\n",
        "    .execute()\n",
        "\n",
        "deltaTable.toDF().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_xfuzNhaSKa",
        "outputId": "f821ed19-27a3-4b82-8adf-a9c4688cda35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+\n",
            "| id|\n",
            "+---+\n",
            "|  0|\n",
            "|  1|\n",
            "|  2|\n",
            "|  3|\n",
            "|  4|\n",
            "|  5|\n",
            "|  6|\n",
            "|  7|\n",
            "|  8|\n",
            "|  9|\n",
            "| 10|\n",
            "| 11|\n",
            "| 12|\n",
            "| 13|\n",
            "| 14|\n",
            "| 15|\n",
            "| 16|\n",
            "| 17|\n",
            "| 18|\n",
            "| 19|\n",
            "+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Update the Table"
      ],
      "metadata": {
        "id": "vYC67bAkadB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data = spark.range(5, 10)\n",
        "data.write.format(\"delta\").mode(\"overwrite\").save(\"/tmp/delta-table\")\n",
        "deltaTable.toDF().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1K32THcabi7",
        "outputId": "e294fac6-57b5-43af-9472-19cc1c850896"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+\n",
            "| id|\n",
            "+---+\n",
            "|  7|\n",
            "|  8|\n",
            "|  9|\n",
            "|  5|\n",
            "|  6|\n",
            "+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Update every even value by adding 100 to it"
      ],
      "metadata": {
        "id": "xkzfmTw2avKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "deltaTable.update(\n",
        "    condition=expr(\"id % 2 == 0\"),\n",
        "    set={\"id\": expr(\"id + 100\")})\n",
        "\n",
        "deltaTable.toDF().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEZzVEmGapKN",
        "outputId": "b43b7749-4bc4-40c2-9d92-5b8cbd32056e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+\n",
            "| id|\n",
            "+---+\n",
            "|  7|\n",
            "|108|\n",
            "|  9|\n",
            "|  5|\n",
            "|106|\n",
            "+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Delete every **even** value"
      ],
      "metadata": {
        "id": "_hGzpW4Ma5fO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "deltaTable.delete(condition=expr(\"id % 2 == 0\"))\n",
        "deltaTable.toDF().show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0F3kmPga2Mc",
        "outputId": "f5bb6457-186e-4086-8476-92b6a9176e76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+\n",
            "| id|\n",
            "+---+\n",
            "|  7|\n",
            "|  9|\n",
            "|  5|\n",
            "+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read old version of data using time travel"
      ],
      "metadata": {
        "id": "TWP0FEq7bQ9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(\"/tmp/delta-table\")\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMsUHNoyFF1S",
        "outputId": "09de4d3c-0ee1-4702-9118-80ff948808d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+\n",
            "| id|\n",
            "+---+\n",
            "|  2|\n",
            "|  3|\n",
            "|  4|\n",
            "|  0|\n",
            "|  1|\n",
            "+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# cleanup"
      ],
      "metadata": {
        "id": "iWea19o9bVth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.rmtree(\"/tmp/delta-table\")"
      ],
      "metadata": {
        "id": "9396PjVzbW5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#References\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   https://delta.io/learn/getting-started\n",
        "*   https://github.com/delta-io/delta\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HHtou5jOzOF2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Issues Faced\n",
        "\n",
        "I was trying to setup with pip install delta-spark\n",
        "pip install deltalake\n",
        "\n",
        "adding jars package with delta.io and all these were throwing error \n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "Caused by: java.lang.ClassNotFoundException: delta.DefaultSource\n",
        "at java.net.URLClassLoader.findClass(URLClassLoader.java:387)\n",
        "```\n",
        "\n",
        "\n",
        "This was happening when trying to use the delta format in write/read. \n",
        "This is because everytime the **runtime needs to be restarted** after pip installation.\n",
        "\n"
      ],
      "metadata": {
        "id": "yJ2B_aTQzhU_"
      }
    }
  ]
}